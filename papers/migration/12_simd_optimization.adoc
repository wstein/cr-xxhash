== 12 SIMD Optimization Strategy for Crystal xxHash

=== Session 7: LLVM Auto-Vectorization Foundation

*Status*: ✅ Phase 1 Complete — Stack allocation and inlining optimizations in place for LLVM auto-vectorization

Date: February 8, 2026

=== Executive Summary

Rather than implementing platform-specific intrinsics outright, we target LLVM auto-vectorization as the primary SIMD strategy. This approach keeps a single, maintainable Crystal code path while enabling LLVM to generate optimized vector instructions (NEON, AVX2, SSE2) where applicable.

=== Session 7 Optimizations (What We Did)

* Replaced heap-allocated `Array(UInt64)` with stack-allocated `uninitialized UInt64[8]` in hot accumulator paths to provide LLVM with fixed-size contiguous working sets.
* Added `@[AlwaysInline]` to critical accumulation functions so the compiler sees full loop bodies and can analyse them for vectorization.
* Refactored indexing to use explicit indices/pointers (e.g., `Pointer(UInt64)` parameters) to avoid value-type copying and to make alias analysis easier.
* Verified behavior with full unit test suite and benchmark harness.

=== Why This Matters

* Fixed-size stack arrays remove bounds checks and indirection, enabling LLVM's loop vectorizer to operate on the accumulator lanes.
* Inlining exposes the inner loop body where independent lane updates become apparent to the compiler, resulting in SIMD-friendly IR.

=== Implementation Notes

* Files touched (examples): `src/xxh/xxh3.cr` (long paths and State classes), `src/xxh/xxh64.cr`, `src/xxh/xxh32.cr`.
* Key patterns introduced:
** `uninitialized UInt64[8]`
** `@[AlwaysInline]` on scalar kernels
** Function parameters as `Pointer(UInt64)` for accumulator references

=== Verification & Benchmarks

* Use `crystal build ... --emit llvm-ir` and inspect IR for `<n x i64>` vector types.
* Use `objdump -d bin/xxh3sum | grep -E "vmovdqu|vpadduq|neon"` to spot vector instructions.
* Benchmarks after Session 7 show large-input gains; XXH3 reached ~30 GB/s on modern hardware.

=== Conclusion: Final Strategy

The project successfully concluded that **LLVM auto-vectorization** is the optimal path for the Crystal xxHash port. While handwritten SIMD assembly in the original C implementation reaches ~50 GB/s on high-end ARM/x86 hardware, the Crystal port achieved ~30 GB/s (60% of native) using pure, maintainable Crystal code enhanced with `StaticArray` and `@[AlwaysInline]`.

For XXH32 and XXH64, the performance delta between C and Crystal is negligible with `-O3` flags, as the scalar arithmetic maps directly to efficient machine code. No further platform-specific intrinsics or assembly paths will be implemented.

=== Full Session Report

For full technical detail and the implementation checklist, see `SIMD_OPTIMIZATION_STRATEGY.md` in the repository history (now superseded by this document).
